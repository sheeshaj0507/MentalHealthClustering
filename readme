ABOUT
In this program, research paper abstracts from the PubMed medical literature database are clustered under five mental health disorder categories: clinical depression, bipolar disorder, anxiety disorder, post-traumatic stress disorder, and schizophrenia.

This is a text clustering exercise, where the abstracts are preprocessed and cleansed, followed by feature engineering using BERT+GloVe embedding techniques for clustering algorithms. K-Means clustering, Agglomerative clustering, and GMM models are implemented. The models are evaluated using Kappa score and silhouette values, followed by error analysis using accuracy score, classification report, confusion matrix, and additional visualizations. Refer to the report for more details.

PREREQUISITES
Install the following libraries (pip install...):

pandas
numpy
re
string
nltk
seaborn
sklearn
matplotlib
gensim.models
collections
scipy
Download the necessary NLTK resources:

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')
Environment (recommended):

Google Collab (Python 3)
DATASET
A web scraping of the public PubMed database under five mental health disorders (i.e., categories: anxiety disorder, bipolar disorder, clinical depression, post-traumatic stress disorder, and schizophrenia) is performed to generate a file with labels and abstracts. The dataset undergoes data preparation and transformation, with the initial cleansed file provided to ensure the rest of the code runs efficiently.

The dataset consists of 150 words per partition. There are 1000 abstracts with corresponding true categories (i.e., labels), with 200 partitions of abstracts for each category.

These two files are provided:

scraped_pubmed_abstract_150.csv
INSTRUCTIONS TO RUN THE PROGRAM
Install the listed libraries as prerequisites.
Run the 'abstract_extraction.ipynb' file separately to generate the dataset. This is omitted from the main program code as it takes a few minutes to generate the dataset. Hence, the dataset file is imported when running the main program.
Import the 'G9_Assignment1_Text_Clustering.ipynb' file into the environment.
Import the abstract file (dataset) and the GloVe file into Google Collab or your Jupyter Notebook location.
Run each code block with the 'scraped_pubmed_abstract_150.csv' dataset in order and view the results.
Alternatively, the code and results are available in each file without needing to run it again.
